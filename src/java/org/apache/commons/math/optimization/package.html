<html>
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
  -->
    <!-- $Revision$ -->
<body>
<p>
This package provides common interfaces for the optimization algorithms
provided in sub-packages. The main interfaces defines objective functions
and optimzers.
</p>
<p>
Objective functions interfaces are intended to be implemented by
user code to represent the problem to minimize or maximize. When the goal is to
minimize, the objective function is often called a cost function. Objective
functions can be either scalar or vectorial and can be either differentiable or
not. There are four different interfaces, one for each case:
<ul>
  <li>{@link org.apache.commons.math.optimization.ScalarObjectiveFunction
      ScalarObjectiveFunction}</li>
  <li>{@link org.apache.commons.math.optimization.ScalarDifferentiableObjectiveFunction
      ScalarDifferentiableObjectiveFunction}</li>
  <li>{@link org.apache.commons.math.optimization.VectorialObjectiveFunction
      VectorialObjectiveFunction}</li>
  <li>{@link org.apache.commons.math.optimization.VectorialDifferentiableObjectiveFunction
      VectorialDifferentiableObjectiveFunction}</li>
</ul>
</p>

<p>
</p>

<p>
Optimizers are the algorithms that will either minimize or maximize, the objective function
by changing its input variables set until an optimal set is found. There are only three
interfaces defining the common behavior of optimizers, one for each type of objective
function except {@link org.apache.commons.math.optimization.VectorialObjectiveFunction
VectorialObjectiveFunction}:
<ul>
  <li>{@link org.apache.commons.math.optimization.ScalarOptimizer
      ScalarOptimizer}</li>
  <li>{@link org.apache.commons.math.optimization.ScalarDifferentiableOptimizer
      ScalarDifferentiableOptimizer}</li>
  <li>{@link org.apache.commons.math.optimization.VectorialDifferentiableOptimizer
      VectorialDifferentiableOptimizer}</li>
</ul>
</p>

<p>
Despite there are only three types of supported optimizers, it is possible to optimize a
transform a non-differentiable {@link
org.apache.commons.math.optimization.VectorialObjectiveFunction VectorialObjectiveFunction}
by transforming into a {@link org.apache.commons.math.optimization.ScalarObjectiveFunction
ScalarObjectiveFunction} thanks to the {@link
org.apache.commons.math.optimization.LeastSquaresConverter LeastSquaresConverter} helper class.
The transformed function can be optimized using any implementation of the {@link
org.apache.commons.math.optimization.ScalarOptimizer ScalarOptimizer} interface.
</p>

<p>
There are also three special implementations which wrap classical optimizers in order to
add them a multi-start feature. This feature call the underlying optimizer several times
in sequence with different starting points and returns the best optimum found or all optima
if desired. This is a classical way to prevent being trapped into a local extremum when
looking for a global one. The multi-start wrappers are {@link
org.apache.commons.math.optimization.MultiStartScalarOptimizer MultiStartScalarOptimizer},
{@link org.apache.commons.math.optimization.MultiStartScalarDifferentiableOptimizer
MultiStartScalarDifferentiableOptimizer} and {@link
org.apache.commons.math.optimization.MultiStartMultiStartVectorialOptimizer
MultiStartVectorialOptimizer}.
</p>
</body>
</html>
